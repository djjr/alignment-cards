const categories = [

  {
    "code": "AP", 
    "name": "Alignment Principles", 
    "pathology": "normative void", 
    "color": "#E6FFE9",
    "description": "Alignment principles are contestable, general-purpose, broadly recognized ethical or social or normative commitments that can serve as warrants for recommending or evaluating an agent's course of action in contexts where alignment and cooperation with others matters."
  }
];


const cards = [

  {
    "category": "AP",
    "name": "Beneficence",
    "definition": "Act to promote the well-being of others.",
    "human": "Seeking to improve others' conditions, not just avoid harm.",
    "organizational": "Pursuing mission outcomes that serve societal good.",
    "professional": "Working in a client's or patient's best interest, not just meeting baseline duties.",
    "machine": "Designing systems that anticipate and promote human flourishing.",
    "expand": {
      "human": "Beneficence in human relationships goes beyond avoiding harm — it's the choice to proactively improve others' conditions. Acts of kindness, generosity, or support foster alignment by building mutual care and reinforcing shared well-being as a goal.",
      "humanref": "https://scholarworks.umb.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1001&context=philosophy_faculty_pubs",
      "organizational": "Organizations demonstrate beneficence when they actively pursue outcomes that advance human or societal welfare. Alignment requires more than compliance or profit-seeking; it asks whether the institution's behavior consistently improves the world it operates in.",
      "professional": "Professionals practice beneficence when they aim not merely to satisfy technical standards, but to serve the interests and flourishing of those they're entrusted to help. This principle grounds many fiduciary duties and ethical codes — it positions expertise in service to others.",
      "machine": "For intelligent systems, beneficence calls for design that does more than minimize harm — it calls for the active promotion of human goals, health, learning, or equity. Aligned systems should be oriented toward supporting well-being as a first-class outcome."
    }
    "failureModes": {
      "human": "Human Failure Mode is blah blah blah",
      "organizational": "Expect machine ref below not to show up since there is no machine failure mode"
      "machineref": "https://scholarworks.umb.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1001&context=philosophy_faculty_pubs",
    }
    },
    { 
      "category": "AB", 
      "name": "An AB Category card", 
      "definition": "basic definition that works across four domains", 
      "human": "BRIEFLY: how does it manifest in the human intelligence alignment context?", 
      "organizational": "BRIEFLY: how does it manifest in the organizational intelligence alignment context?", 
      "professional": "BRIEFLY: how does it manifest in the expert intelligence alignment context?", 
      "machine": "BRIEFLY: how does it manifest in the machine intelligence alignment context?", 
      "expand": { 
        "human": "Elaborate, give concrete examples, raise issues.", 
        "professional": "Elaborate, give concrete examples, raise issues.", 
        "machine": ""
      },
      "failureModes": {
        "human": "Elaborate, give concrete examples, raise issues.", 
        "organizational": "Elaborate, give concrete examples, raise issues.", 
        "professional": "Elaborate, give concrete examples, raise issues.", 
        "machine": "Elaborate, give concrete examples, raise issues."
      }
    },
    { 
      "category": "AB", 
      "name": "Some AB category card", 
      "definition": "basic definition that works across four domains", 
      "human": "BRIEFLY: how does it manifest in the human intelligence alignment context?", 
      "organizational": "BRIEFLY: how does it manifest in the organizational intelligence alignment context?", 
      "professional": "BRIEFLY: how does it manifest in the expert intelligence alignment context?", 
      "machine": "BRIEFLY: how does it manifest in the machine intelligence alignment context?", 
      "expand": { 
        "human": "Elaborate, give concrete examples, raise issues.", 
        "organizational": "Elaborate, give concrete examples, raise issues.", 
        "professional": "Elaborate, give concrete examples, raise issues.", 
        "machine": "Elaborate, give concrete examples, raise issues."
      }
    }


]
